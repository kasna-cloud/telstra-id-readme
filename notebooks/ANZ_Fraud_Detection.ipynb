{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "fraud-detection-example.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqcZQpdcOyVn",
    "colab_type": "text"
   },
   "source": [
    "# 0. Introduction\n",
    "\n",
    "This notebook runs a fraud detection model for credit-cards transactions using the Google Cloud Platform (GCP). GCP has several advantages related to Machine Learning. It allows to store and process large datasets that do not fit in memory, in a distributed manner. It provides flexibility and allows to automatically scale the computing ressources based on your needs (for instance different scale tiers are offered with different prices and performances). In addition Google Cloud provides several ML API (e.g. Vision, Speech recognition) leveraging state of the art pre-trained models, making it easy to train and use in production performant models.\n",
    "\n",
    "In this notebook we will execute code to process data, train a Tensorflow model with hyperparameter tuning, run predictions on new data and assess model performances.\n",
    "We will leverage the following GCP capabilities:\n",
    "- Google Big Query\n",
    "- Cloud DataFlow (Apache-Beam + Tensorflow-Transform)\n",
    "- Cloud ML Engine (Tensorflow).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Before you start, you will need to:**\n",
    "\n",
    "* Create a Google Cloud project and a bucket in Google Cloud Storage\n",
    "* Install gcloud SDK to run gcloud commands: https://cloud.google.com/sdk/downloads\n",
    "\n",
    "**You can also:**\n",
    "\n",
    "* Go through the python code available on [GitHub here](https://github.com/GoogleCloudPlatform/professional-services/tree/master/examples/cloudml-fraud-detection).\n",
    "\n",
    "**Recommendation to use this notebook:**\n",
    "\n",
    "This notebook provides one example to approach the fraud detection problem and there are many other ways it can be tackled or improved. Once you have a good understanding of the current solution, try to add modifications to the code, to run it in GCP and see the impact.\n",
    "\n",
    "Throughout the notebook, we provide suggestions for improvements, feel free to try some of these or your own ideas.\n",
    "\n",
    "\n",
    "\n",
    "**Acknowledgements:**\n",
    "\n",
    "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Universit√© Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http://mlg.ulb.ac.be/BruFence and http://mlg.ulb.ac.be/ARTML.\n",
    "Dataset provided thanks to: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2fzNA9AXtDz",
    "colab_type": "text"
   },
   "source": [
    "# 1. Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUcVO2KszHfU",
    "colab_type": "text"
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Make sure that the following requirements are verified:\n",
    "\n",
    "```\n",
    "tensorflow==1.13.1\n",
    "apache_beam[gcp]==2.12.0\n",
    "tensorflow-transform==0.4.0\n",
    "matplotlib\n",
    "sklearn\n",
    "numpy\n",
    "scipy\n",
    "```\n",
    "\n",
    "Otherwise the notebook might not run as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A73k0uPOzgtT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%%bash\n",
    "python2 -m pip install tensorflow==1.13.1 --user\n",
    "python2 -m pip install apache_beam[gcp]==2.12.0 --user\n",
    "python2 -m pip install tensorflow-transform==0.4.0 --user\n",
    "python2 -m pip install matplotlib --user\n",
    "python2 -m pip install sklearn --user\n",
    "python2 -m pip install numpy --user\n",
    "python2 -m pip install scipy --user"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project information\n",
    "\n",
    "Hard-code your project information as environment variables to be used in the next steps.\n",
    "* BUCKET_ID is the name of your bucket to store outputs for this example "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%env BUCKET_ID=anz-uc-team-1-storage\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wE1hDBHNzQfZ",
    "colab_type": "text"
   },
   "source": [
    "## Set your GCP project id"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mMDqSpeWdTv1",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT_ID"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDMUB4zWcrkE",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set up the dataset using Google BigQuery\n",
    "\n",
    "In your project, create a BigQuery dataset and create a table from the data stored in GCP public bucket by running the commands below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKQpJEYlvPAt",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set public path to the data, GBQ dataset and table name, **please leave as is**:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A_v9ATnfXtEF",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "source": [
    "%env DATASET_PUBLIC_PATH=gs://fraud-detection-example/creditcard_proc.csv\n",
    "%env DATASET=fraud_detection\n",
    "%env DATASET_LOCATION=US\n",
    "%env BQ_TABLE_NAME=raw_data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3buGJ-WWZFzS",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%bash\n",
    "bq mk --dataset --data_location $DATASET_LOCATION --project_id $PROJECT_ID $DATASET\n",
    "bq load --project_id $PROJECT_ID --autodetect \\\n",
    "--source_format=CSV $DATASET.$BQ_TABLE_NAME $DATASET_PUBLIC_PATH"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN_HMpzFOyWR",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clone the git repository containing the necessary code\n",
    "\n",
    "It contains python code to process data, train a tensorflow model and run predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AdEHrw6XtEL",
    "colab_type": "text"
   },
   "source": [
    "**Note: you may need to request access to the GCP bucket and repository**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zenhdMKSXtEL",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "source": [
    "!git clone https://github.com/kasna-cloud/professional-services.git"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfoCCAPJH3fk",
    "colab_type": "text"
   },
   "source": [
    "**Current timestamp for unique naming**\n",
    "\n",
    "We use the current timestamp as a string to ensure unique naming through the different steps of the process."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SInKecFOVaqb",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "current_time = str(time.time()).replace('.', '')\n",
    "current_time"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W877mejfV1K_",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Brief data exploration\n",
    "\n",
    "\n",
    "The dataset is a list of credit card transactions with features describing the transactions and a flag if the transaction was fraudulent.\n",
    "The features include the time of the transaction, its amount and 28 components from a PCA.\n",
    "\n",
    "See [here](https://www.kaggle.com/mlg-ulb/creditcardfraud/data) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67W4mUzpVaEc",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data from GBQ into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mekm1pgRXY-Q",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%bash\n",
    "python2 -m pip install pandas-gbq --user"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B9uU_cuVXbtS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import pandas as pd\n",
    "from pandas.io import gbq"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lY-VhWmtXcag",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "project_id = os.environ.get('PROJECT_ID')\n",
    "table_name = project_id + '.fraud_detection.raw_data'\n",
    "\n",
    "data = gbq.read_gbq(query='select * from `{}` limit 1000'.format(table_name),\n",
    "                    project_id=project_id, dialect='standard')\n",
    "print data.shape\n",
    "data.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9oRemobavdb",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Count occurrences for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IgKsJWuMaVgH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "**Features overview**"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbpUow7ubJ0i",
    "colab_type": "text"
   },
   "source": [
    "pd.concat([data.mean(), data.std()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O52zO4OPyFw",
    "colab_type": "text"
   },
   "source": [
    "The V1-V28 PCA components are centered but not all features. We will center and scale each feature in the data processing step using the *Tensorflow-Transform* library."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "29Cv225aXtES",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "**Suggestions for improvements**\n",
    "\n",
    "Try to further explore the data and create additional features. For instance:\n",
    "- features describing preceeding transactions\n",
    "- feature percentiles\n",
    "- transactions clustering to then compute the distances between a transaction and each cluster."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yfSnDRMXtET",
    "colab_type": "text"
   },
   "source": [
    "<h1>3. Run data preprocessing in Google Cloud Dataflow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgO79t8NXtEU",
    "colab_type": "text"
   },
   "source": [
    "In this part we run the data preprocessing in Google Cloud Dataflow using the Apache-Beam and Tensorflow-Transform libraries.\n",
    "\n",
    "**Brief overview of the tools:**\n",
    "- Dataflow: data processing framework in Google Cloud relying on Apache beam. Scales well to multiple workers (more information [here](https://cloud.google.com/dataflow/)).\n",
    "- TFT: Wrapper on top of Tensorflow to do some preprocessing operation (e.g. standardizing data, preprocessing text). There are a couple of advantages to it: it scales with Dataflow and the graph can be used for inference (more information [here](https://github.com/tensorflow/transform)).\n",
    "\n",
    "**This step includes the following:**\n",
    "- Reads data from BigQuery.\n",
    "- Adds hash key value to each row: we add a hash key identifier to each row to be able to score data and compare with the true labels later on.\n",
    "- Normalizes data.\n",
    "- Shuffles and splits data in train / validation / test sets.\n",
    "- Oversamples train data: to make up for the strong class imbalance and allow for proper training in batches.\n",
    "- Stores data as TFRecord, the preferred Tensorflow format for data storage which allows to input data in Tensorflow graphs more efficiently.\n",
    "- Splits and stores test data into separate labels and features files, to ensure that inference is done on non-labelled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oOoiwndT2qi",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Output path**\n",
    "\n",
    "Hard-code the output path of data processing to be used in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D7oQpxe6XtEY",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%\n",
    "os.environ['DATAFLOW_OUTPUT_DIR'] = 'data_flow_output_dir-{}/'.format(current_time) \n",
    "!echo $DATAFLOW_OUTPUT_DIR"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZTxJDAGt7kf",
    "colab_type": "text"
   },
   "source": [
    "**Launch data processing job**\n",
    "\n",
    "You need to specify the name of the table you stored in BigQuery and input it with the '--bq_table' argument. In addition you need to specify several other arguments (see python --help command)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5qUJ2-rt5wU",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You may have to run the following before starting the preprocessing job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ms5enLNluAqG",
    "colab_type": "text"
   },
   "source": [
    "%%bash\n",
    "gcloud compute networks create default\n",
    "gcloud services enable dataflow.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtR1QeB4T3NX",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start the preprocessing job.\n",
    "\n",
    "NOTE: The job below takes about half an hour to run. We've already ran it and you could\n",
    "find the output in `team-storage/data_flow_output_dir`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JN-Yz84Q_M4t",
    "colab_type": "text",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%bash\n",
    "cd professional-services/examples/cloudml-fraud-detection/\n",
    "python preprocess.py \\\n",
    "--cloud \\\n",
    "--bq_table $BQ_TABLE_NAME \\\n",
    "--output_dir ${DATAFLOW_OUTPUT_DIR} \\\n",
    "--project_id $PROJECT_ID \\\n",
    "--bucket_id $BUCKET_ID \\\n",
    "--subnet https://www.googleapis.com/compute/v1/projects/anz-uc-host/regions/australia-southeast1/subnetworks/anz-uc-team-1-subnet \\\n",
    "--zone australia-southeast1-a"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you didn't run the command above then setup your environment variable to point to prepopulated data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%env DATAFLOW_OUTPUT_DIR=data_flow_output_dir/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "**Monitor your DataFlow job in the console**\n",
    "\n",
    "Go to [the GCP DataFlow console](https://cloud.google.com/dataflow/), select 'view console', click on your job. You can see the evolution of the processing through each step.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "**List files in output directory**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!gsutil ls gs://$BUCKET_ID/$DATAFLOW_OUTPUT_DIR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0DWJ9P0WGAu",
    "colab_type": "text"
   },
   "source": [
    "**Suggestions for improvements**\n",
    "\n",
    "The current solution stores the processed data as TFRecords files. These is ideal from a performance perspective, but may not be ideal in term of readability, if for instance you would like to debug the processing pipeline and read the output. Instead of using the `tfrecordio.WriteToTFRecord` function of the current solution, you can use `beam.io.WriteToText` that will store the data as readable text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPoZbDLZXtEe",
    "colab_type": "text"
   },
   "source": [
    "# 4. Training in Google Cloud ML Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4-DIMWBXtEf",
    "colab_type": "text"
   },
   "source": [
    "**Set up environment variables**\n",
    "\n",
    "Tensorflow can store temporary model files and the trained model to a given directory. To this end, we hard-code the output path for the training sep as well as the job name, to be used as arguments in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EsSTt2nsXtEf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "os.environ['TRAINING_JOB_NAME'] = 'fraud_detection_training_job_{}'.format(\n",
    "    current_time)\n",
    "os.environ['TRAINING_OUTPUT_DIR'] = 'gs://{}/training_output_dir-{}'.format(\n",
    "    os.environ['BUCKET_ID'], current_time)\n",
    "print os.environ['TRAINING_JOB_NAME'], os.environ['TRAINING_OUTPUT_DIR']"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-FeHT3EXtEi",
    "colab_type": "text"
   },
   "source": [
    "**Set hyperparameters search configuration**\n",
    "\n",
    "The training step includes hyperparameter tuning. Hyperparameter tuning (described in more detail here: https://cloud.google.com/blog/big-data/2018/03/hyperparameter-tuning-on-google-cloud-platform-is-now-faster-and-smarter) is the concept of training and evaluating different parametrizations of a model to then pick the best performing one.\n",
    "For this purpose we need to indicate which parameters we want to test and the range we want to try.\n",
    "\n",
    "The ML-engine command takes in input a '.yaml' file that contains the configuration to use for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9u6UFS9xXtEj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%%writefile professional-services/examples/cloudml-fraud-detection/hyperparams.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    maxTrials: 10\n",
    "    maxParallelTrials: 2\n",
    "    enableTrialEarlyStopping: True\n",
    "    goal: MAXIMIZE\n",
    "    hyperparameterMetricTag: auc_precision_recall\n",
    "    params:\n",
    "    - parameterName: first_layer_size\n",
    "      type: INTEGER\n",
    "      minValue: 5\n",
    "      maxValue: 50\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: num_layers\n",
    "      type: INTEGER\n",
    "      discreteValues:\n",
    "      minValue: 1\n",
    "      maxValue: 2\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: dropout\n",
    "      type: DOUBLE\n",
    "      minValue: 0.10\n",
    "      maxValue: 0.50\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.0001\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LOG_SCALE"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOUlmoKXXtEl",
    "colab_type": "text"
   },
   "source": [
    "**Submit training job**\n",
    "\n",
    "You can specify the maximum number of training steps with the '--max_steps' argument.\n",
    "\n",
    "NOTE: The job below takes about half an hour to run. We've already ran it and you could\n",
    "find the output in `team-storage/training_output_dir`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e3KKI8ZaXtEn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%%bash\n",
    "cd professional-services/machine-learning/solutions/fraud_detection/\n",
    "MAX_STEP=10000\n",
    "gcloud ml-engine jobs submit training $TRAINING_JOB_NAME \\\n",
    "--module-name trainer.task \\\n",
    "--staging-bucket gs://${BUCKET_ID} \\\n",
    "--package-path ./trainer \\\n",
    "--region=us-central1 \\\n",
    "--runtime-version 1.5 \\\n",
    "--config=hyperparams.yaml \\\n",
    "-- \\\n",
    "--input_dir gs://${BUCKET_ID}/${DATAFLOW_OUTPUT_DIR} \\\n",
    "--output_dir ${TRAINING_OUTPUT_DIR} \\\n",
    "--max_steps $MAX_STEP"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you didn't run the command above then setup your environment variable to point to prepopulated data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%env TRAINING_OUTPUT_DIR=gs://anz-uc-team-1-storage/training_output_dir\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHE6pzkhXtEv",
    "colab_type": "text"
   },
   "source": [
    "**Monitor overall training in Google Cloud ML-engine**\n",
    "\n",
    "You can also monitor the overall training in GCP, access the logs and monitor the results of hyperparameter tuning in the ML-engine console:\n",
    "\n",
    "Go to the console: https://cloud.google.com/ml-engine/ and select 'View Console'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfgazJtMe5At",
    "colab_type": "text"
   },
   "source": [
    "**Suggestions for improvements**\n",
    "\n",
    "The current data processing applies oversampling to the positive class. There are other ways one can deal with class imbalance for instance:\n",
    "- undersampling the negative class\n",
    "- change the loss functions to use different weights.\n",
    "\n",
    "Feel free to change the code to implement some of these options and see how they perform."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k1IPrVQ2fh0J",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 5. Inferences in Google Cloud ML Engine"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGkxEg4MXtEv",
    "colab_type": "text"
   },
   "source": [
    "Once our model is trained and stored in Google Cloud Storage, we can add it to Cloud ML Engine and use it for batch inference on new data, among other things.\n",
    "Different versions of the same model can be stored in the ML Engine. We will specify a name for the model and a unique name for the current version, based on current timestamp."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wKg3XVP8XtEw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "**Pick the best model trial from hyperparameter tuning to use moving forward**\n",
    "\n",
    "After hyperparameter tuning we may have to pick between different trials and select the best performing one to use for inference. The next command defines which version to use moving forward. In this example the trial picked is 'TRIAL_NUMBER=1' but **you should adapt to pick the best performing model that you obtained after training.**"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEfi9pvDCYvV",
    "colab_type": "text"
   },
   "source": [
    "%env TRIAL_NUMBER=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsbPXri_CuWD",
    "colab_type": "text"
   },
   "source": [
    "**Set up environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sTTQnFv_C7Lz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "os.environ['MODEL_NAME'] = 'fraud_detection_test_nb'\n",
    "os.environ['MODEL_VERSION'] = 'v_{}'.format(time.time()).replace('.', '')\n",
    "temp = !echo $(gsutil ls ${TRAINING_OUTPUT_DIR}/trials/${TRIAL_NUMBER}/export/exporter/ | tail -1)\n",
    "os.environ['MODEL_SAVED_NAME'] = temp[0]\n",
    "del temp\n",
    "print os.environ['MODEL_SAVED_NAME']"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iq9vzcOwCfbN",
    "colab_type": "text"
   },
   "source": [
    "**Your models are stored as .pb files in Google Cloud Storage.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O1oaIJupCUMc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "List of trials in Google Cloud Storage"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBIx7-5NXtEy",
    "colab_type": "text"
   },
   "source": [
    "!gsutil ls ${TRAINING_OUTPUT_DIR}/trials/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tx2OIvHyOe2_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "Files exported for the trial you selected:"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbmBQ3cBfsyh",
    "colab_type": "text"
   },
   "source": [
    "!gsutil ls $MODEL_SAVED_NAME"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NR_7-pBMXtEy",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "**Create and save model in Google Cloud ML-engine**\n",
    "\n",
    "We first need to add a new model to Cloud ML-engine.."
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucpc-KM7HPdo",
    "colab_type": "text"
   },
   "source": [
    "%%bash\n",
    "gcloud ml-engine models create $MODEL_NAME \\\n",
    "--regions us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83OwbdtIXtE1",
    "colab_type": "text"
   },
   "source": [
    ".. and add the current version to the GCP model created, by specifying the path to the model we would like to use from Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MlrZh45TXtE1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%%bash\n",
    "gcloud ml-engine versions create $MODEL_VERSION \\\n",
    "--model $MODEL_NAME \\\n",
    "--origin $MODEL_SAVED_NAME \\\n",
    "--runtime-version 1.5"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paRnUsWjXtE5",
    "colab_type": "text"
   },
   "source": [
    "Now that the model is saved, we can launch a inference job by indicating the name of the model we just stored and the path to the data to be scored (here the test sample data from the DataFlow step)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5s175Je-XtE5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "**Set up environment variables**\n",
    "\n",
    "We need to specify the following:\n",
    "\n",
    "* JOB_NAME: unique name for inference job\n",
    "* FEATURES_INPUT_PATH: the path to the features to use for prediction (here it is in the output of the DataFlow job)\n",
    "* PREDICTIONS_OUTPUT_PATH: the path to the directory to store the predictions to."
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB_Z2jnHJkfx",
    "colab_type": "text"
   },
   "source": [
    "os.environ['JOB_NAME'] = '{}_{}'.format(\n",
    "    os.environ['MODEL_NAME'],\n",
    "    os.environ['MODEL_VERSION'])\n",
    "os.environ['FEATURES_INPUT_PATH'] = 'gs://{}/{}split_data/split_data_TEST_features.txt*'.format(\n",
    "    os.environ['BUCKET_ID'],\n",
    "    os.environ['DATAFLOW_OUTPUT_DIR'])\n",
    "os.environ['PREDICTIONS_OUTPUT_PATH'] = 'gs://{}/predictions/{}'.format(\n",
    "    os.environ['BUCKET_ID'],\n",
    "    os.environ['JOB_NAME'])\n",
    "print os.environ['FEATURES_INPUT_PATH']\n",
    "print os.environ['PREDICTIONS_OUTPUT_PATH']\n",
    "print os.environ['JOB_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVv54jVdXtE9",
    "colab_type": "text"
   },
   "source": [
    "**Submit prediction job**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Xhb4UxBXtE-",
    "colab_type": "text"
   },
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs submit prediction $JOB_NAME \\\n",
    "--model $MODEL_NAME \\\n",
    "--input-paths $FEATURES_INPUT_PATH \\\n",
    "--output-path $PREDICTIONS_OUTPUT_PATH \\\n",
    "--region us-central1 \\\n",
    "--data-format TEXT \\\n",
    "--version $MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k869CwkDXtE_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "**Monitor prediction job in Google Cloud ML-engine**\n",
    "\n",
    "You can monitor the prediction job in the GCP ML Engine console:\n",
    "\n",
    "https://cloud.google.com/ml-engine/ and select 'View Console'."
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e4XM_arXtFC",
    "colab_type": "text"
   },
   "source": [
    "# 6. Assess model performances on out-of-sample data\n",
    "\n",
    "We can assess how well our model is performing on the data previously scored. For this purpose we will compare predictions to true labels and derive the precision-recall curve and its AUC. Precision-recall curve AUC is a relevant metric to assess our model's performances as it reflects the fraction of the fraudulent transactions we are able to predict and the accuracy of these predictions. Compared to other metrics it is less sensitive to the strong class imbalance of this example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RZwkH1KjXtFC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def extract_from_json(path, key, values, proc=(lambda x: x)):\n",
    "  \"\"\"Extracts and parses data from json files and returns a dictionary.\n",
    "\n",
    "  Args:\n",
    "    path: string, path to input data.\n",
    "    key: string, name of key column.\n",
    "    values: string, name of column containing values to extract.\n",
    "    proc: function, used to process values from input. Follows the signature:\n",
    "      * Args:\n",
    "        * x: string or tuple of string\n",
    "      * Returns:\n",
    "        string\n",
    "\n",
    "  Returns:\n",
    "    Dictionary of parsed data.\n",
    "  \"\"\"\n",
    "\n",
    "  res = {}\n",
    "  keys = []\n",
    "  with open(path) as f:\n",
    "    for line in f:\n",
    "      line = json.loads(line)\n",
    "      item_key = proc(line[key])\n",
    "      res[item_key] = line[values]\n",
    "      keys.append(item_key)\n",
    "  unique_keys = [key for key in keys if keys.count(key) == 1]\n",
    "  return {k: res[k] for k in unique_keys}\n",
    "\n",
    "def compute_and_print_pr_auc(labels, probabilities):\n",
    "  \"\"\"Computes statistic on predictions, based on true labels.\n",
    "\n",
    "  Prints precision-recall curve AUC and writes the curve as a JPG image to the\n",
    "  specified directory.\n",
    "\n",
    "  Args:\n",
    "    labels: np.array, vector containing true labels.\n",
    "    probabilities: np.array, 2-dimensional vector containing inferred\n",
    "      probabilities.\n",
    "  \"\"\"\n",
    "\n",
    "  average_precision = average_precision_score(labels, probabilities[:, 1])\n",
    "\n",
    "  precision, recall, _ = precision_recall_curve(labels, probabilities[:, 1])\n",
    "  plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "  plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.title(\n",
    "    'Precision-Recall curve: AUC={0:0.2f}'.format(average_precision))\n",
    "  plt.plot()\n",
    "  print 'Precision-Recall AUC: {0:0.2f}'.format(average_precision)\n",
    "\n",
    "def run(labels_path, predictions_path):\n",
    "  \"\"\"Reads input data and runs analysis on predictions.\n",
    "\n",
    "  Args:\n",
    "    labels_path: string, path to true labels.\n",
    "    predictions_path: string, path to inferred probabilities.\n",
    "  \"\"\"\n",
    "\n",
    "  labels = extract_from_json(labels_path, 'key', 'Class')\n",
    "  proba = extract_from_json(\n",
    "    predictions_path, 'key', 'probabilities', proc=(lambda x: x[0]))\n",
    "\n",
    "  keys = set(labels.keys()) & set(proba.keys())\n",
    "  labels = np.array([labels[key] for key in keys])\n",
    "  proba = np.array([proba[key] for key in keys])\n",
    "\n",
    "  compute_and_print_pr_auc(\n",
    "    labels=labels, probabilities=proba)\n",
    "\n",
    "run(\n",
    "  labels_path='labels.txt',\n",
    "  predictions_path='predictions.txt')\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AP_Me6KdYoWP",
    "colab_type": "text"
   },
   "source": [
    "**Suggestions for improvements**\n",
    "\n",
    "Once the classification model is trained and tested, we can think about implementation and how to take action using the model. One important question is to decide which action should be taken based on the model output for a given transaction.\n",
    "\n",
    "In this classification example the output is the probability that a transaction is fraudulent. We need to decide when to actually flag a transaction as fraudulent. There are several ways to approach the problem (non exhaustive and non mutually exclusive):\n",
    "- Set a fixed threshold for the probabilities; above the threshold the transaction is flagged, below it is not.\n",
    "- Balance the cost and benefits of true / false positives / negatives and optimize the overall profit (linear optimization problem).\n",
    "- Flag a transaction as fraudulent in a probabilistic manner (depending on the output of the model), the higher the output probability, the more likely we will flag it.\n",
    "\n",
    "The approach to take depends on the business problem to solve:\n",
    "- The cost / benefits of classification / miss-classification.\n",
    "- The cost of checking that a transaction is actually fraudulent, once we flagged it.\n",
    "- If the business wants to gather data to further improve the model.\n",
    "- The business impact of acting in a probabilistic manner.\n",
    "\n",
    "Feel free to explore different options. You can also find more online: https://www.cs.ubc.ca/~murphyk/Teaching/CS340-Fall07/dtheory.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dq34_OT3aol-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}